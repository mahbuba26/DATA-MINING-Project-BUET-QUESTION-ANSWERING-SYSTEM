{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14291100,"sourceType":"datasetVersion","datasetId":9122238},{"sourceId":14300651,"sourceType":"datasetVersion","datasetId":9128853},{"sourceId":14731531,"sourceType":"datasetVersion","datasetId":9413692},{"sourceId":14754556,"sourceType":"datasetVersion","datasetId":9430312}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers sentence-transformers spacy protobuf==3.20.3\n!pip install torch torchvision torchaudio torch_geometric\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nimport pandas as pd\nimport numpy as np\nimport spacy\nimport ast\nfrom typing import List, Dict\nfrom sentence_transformers import SentenceTransformer, CrossEncoder\nfrom transformers import pipeline\nimport torch_geometric\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:43:20.210458Z","iopub.execute_input":"2026-02-04T17:43:20.210734Z","iopub.status.idle":"2026-02-04T17:44:04.556725Z","shell.execute_reply.started":"2026-02-04T17:43:20.210710Z","shell.execute_reply":"2026-02-04T17:44:04.556089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nedge_embeddings = np.load(\"/kaggle/input/edge-embedding/conceptnet_edge_embeddings (1).npy\")\n ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df = pd.read_csv(\"/kaggle/input/canndy/pairs_extracted.csv\")\nconceptnet_df = pd.read_csv(\"/kaggle/input/mintoc/conceptnet_df_clean.csv\",sep=\"\\t\",\n    header=None)  # relation, head\n\n#conceptnet_df.columns = [\"relation\", \"head\", \"tail\", \"weight\"]\n\nconceptnet_df = pd.read_csv(\"/kaggle/input/mintoc/conceptnet_df_clean.csv\")\nconceptnet_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:44:04.558081Z","iopub.execute_input":"2026-02-04T17:44:04.559307Z","iopub.status.idle":"2026-02-04T17:44:12.299473Z","shell.execute_reply.started":"2026-02-04T17:44:04.559272Z","shell.execute_reply":"2026-02-04T17:44:12.298837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***Recall candidates (high recall, low precision)***","metadata":{}},{"cell_type":"code","source":"def recall_edges(concepts,\n                 numbers,\n                 units,\n                 relations,\n                 qa_text,\n                 sim_threshold=0.1,\n                 recall_top_k=60):\n\n    # --- 1️⃣ Concept-based candidate filtering (safe & fast) ---\n    #concept_set = set(norm(c) for c in concepts)\n\n    concept_set = set(concepts)\n\n    mask = (\n        conceptnet_df[\"head\"].isin(concept_set) |\n        conceptnet_df[\"tail\"].isin(concept_set)\n    )\n\n    candidate_idx = np.where(mask)[0]\n    if len(candidate_idx) == 0:\n        return []\n\n    # --- 2️⃣ Enriched QA text (semantic signal injection) ---\n    extra_signal = \" \".join(\n        list(concepts) +\n        list(relations) +\n        [f\"{n} {u}\" for n, u in zip(numbers, units)]\n    )\n\n    enriched_qa_text = qa_text + \" \" + extra_signal\n\n    # --- 3️⃣ QA embedding ---\n    qa_emb = bi_encoder.encode(\n        enriched_qa_text,\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    ).reshape(-1)\n\n    # --- 4️⃣ Edge similarity (edge_text already embedded) ---\n    edge_embs = edge_embeddings[candidate_idx]\n    sims = np.dot(edge_embs, qa_emb)\n\n    # --- 5️⃣ Weight as soft prior (non-dominant) ---\n    weights = conceptnet_df.iloc[candidate_idx][\"weight\"].values\n    weights = np.log1p(weights)\n    sims = sims * (1.0 + 0.3 * weights)\n\n    # --- 6️⃣ Filter + rank ---\n    keep = sims >= sim_threshold\n    idx = candidate_idx[keep]\n    sims = sims[keep]\n\n    order = np.argsort(-sims)[:recall_top_k]\n\n    return [(int(idx[i]), float(sims[i])) for i in order]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:44:16.673674Z","iopub.execute_input":"2026-02-04T17:44:16.673985Z","iopub.status.idle":"2026-02-04T17:44:16.681227Z","shell.execute_reply.started":"2026-02-04T17:44:16.673952Z","shell.execute_reply":"2026-02-04T17:44:16.680442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nbi_encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Cross encoder reranker**","metadata":{}},{"cell_type":"code","source":"from typing import List, Tuple, Optional\nimport math\n\nfrom sentence_transformers import CrossEncoder\n\ncross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", device=\"cuda\")\n\n\ndef rerank_edges(\n    qa_text: str,\n    candidates: List[Tuple[int, float, Optional[List[str]]]],  # (idx, prior_score, path_opt)\n    top_k: int = 40,\n    batch_size: int = 32,\n    include_path_in_prompt: bool = False,\n    combine_with_prior: bool = True,\n    prior_weight: float = 0.3  # only used if combine_with_prior True\n) -> List[Tuple[int, float, Optional[List[str]]]]:\n    \"\"\"\n    Args:\n      candidates: sequence of tuples (idx, prior_score, path) where path may be None or list of str.\n                  If your candidates are (idx,score) you can convert to (idx,score,None).\n      include_path_in_prompt: if True, the QA side of pair will include the hop path context.\n      combine_with_prior: if True, final score = cross_score * (1 + prior_weight * normalized_prior)\n    Returns:\n      list of (idx, final_score, path) sorted by final_score desc (length <= top_k)\n    \"\"\"\n    if not candidates:\n        return []\n\n    # Normalize prior scores (if present)\n    priors = [c[1] if len(c) > 1 and c[1] is not None else 0.0 for c in candidates]\n    max_prior = max(priors) if priors else 1.0\n    min_prior = min(priors) if priors else 0.0\n    def norm_prior(p):\n        if max_prior == min_prior:\n            return 0.0\n        return (p - min_prior) / (max_prior - min_prior)\n\n    # Build texts for cross-encoder: pair of [qa_text (+ optional path), edge_text]\n    texts = []\n    metas = []  # store (idx, prior, path)\n    for idx, prior, *rest in candidates:\n        path = rest[0] if rest else None\n        if include_path_in_prompt and path:\n            left = qa_text + \" Context path: \" + \" -> \".join(path)\n        else:\n            left = qa_text\n        right = conceptnet_df.iloc[int(idx)][\"edge_text\"]\n        texts.append([left, right])\n        metas.append((int(idx), float(prior if prior is not None else 0.0), path))\n\n    # Batched prediction\n    scores = []\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        batch_scores = cross_encoder.predict(batch)\n        scores.extend(batch_scores)\n\n    # Combine and rank\n    results = []\n    for (idx, prior, path), cross_score in zip(metas, scores):\n        final_score = float(cross_score)\n        if combine_with_prior:\n            np_prior = norm_prior(prior)\n            final_score = final_score * (1.0 + prior_weight * np_prior)\n        results.append((idx, final_score, path))\n\n    results.sort(key=lambda x: -x[1])\n    return results[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:45:55.865170Z","iopub.execute_input":"2026-02-04T17:45:55.866059Z","iopub.status.idle":"2026-02-04T17:46:00.031039Z","shell.execute_reply.started":"2026-02-04T17:45:55.866019Z","shell.execute_reply":"2026-02-04T17:46:00.030305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**COT only if ambiguous**","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")\n\nllama = pipeline(\n    \"text-generation\",\n    model=\"meta-llama/Llama-3.1-8B\",\n    max_new_tokens=120,\n    do_sample=False,\n    device_map=\"auto\",\n    return_full_text=False\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:48:45.863823Z","iopub.execute_input":"2026-02-04T17:48:45.864705Z","iopub.status.idle":"2026-02-04T17:49:59.314828Z","shell.execute_reply.started":"2026-02-04T17:48:45.864666Z","shell.execute_reply":"2026-02-04T17:49:59.314260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport json\n\n# llama pipeline already created. Recommend calling with deterministic generation params at call-time:\n# e.g. llama(prompt, temperature=0.0, max_new_tokens=120, do_sample=False)\n\ndef extract_json_from_text(text: str):\n    \"\"\"Find first {...} JSON-like substring and parse it robustly.\"\"\"\n    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n    if not m:\n        return None\n    s = m.group()\n    try:\n        return json.loads(s)\n    except Exception:\n        # Try minimal cleanup: replace single quotes -> double quotes, remove trailing commas\n        s2 = s.replace(\"'\", '\"')\n        s2 = re.sub(r\",\\s*}\", \"}\", s2)\n        s2 = re.sub(r\",\\s*]\", \"]\", s2)\n        try:\n            return json.loads(s2)\n        except Exception:\n            return None\n\ndef cot_disambiguate(\n    qa_text: str,\n    edges: List[Tuple[int, float, Optional[List[str]]]],\n    top_n: int = None,\n    llama_batch: bool = False,\n    temperature: float = 0.0\n) -> List[Tuple[int, float]]:\n    \"\"\"\n    Args:\n      edges: list of (idx, prior_score, path) or (idx, prior_score). Prefer top-k filtered before calling.\n      top_n: if set, limit to top_n edges to query the LLM (recommended small like 10).\n      llama_batch: not used by default (left for advanced batching).\n    Returns:\n      list of (idx, llm_score) sorted desc by llm_score\n    \"\"\"\n    if not edges:\n        return []\n\n    # limit\n    if top_n is not None:\n        edges = edges[:top_n]\n\n    refined = []\n    for item in edges:\n        # unpack forms (idx, score, path) or (idx,score)\n        if len(item) >= 3:\n            idx, prior, path = item\n        else:\n            idx, prior = item\n            path = None\n\n        edge = conceptnet_df.iloc[int(idx)]\n        # prompt: be explicit that ONLY a JSON object should be returned\n        prompt = f\"\"\"Question & Answer:\n{qa_text}\n\nEdge:\n{edge['head']} {edge['relation']} {edge['tail']}\n\nTask: Decide whether the above edge logically supports the answer. Output ONLY a single JSON object with one key \"score\" whose value is a number between 0.0 (no support) and 1.0 (strong support).\nExample valid output:\n{{\"score\": 0.75}}\nDo not add any other text outside the JSON object.\n\"\"\"\n        # call LLM deterministically\n        out = llama(prompt, temperature=temperature, max_new_tokens=120, do_sample=False)[0][\"generated_text\"]\n\n        parsed = extract_json_from_text(out)\n        score = 0.0\n        if parsed and \"score\" in parsed:\n            try:\n                score = float(parsed[\"score\"])\n            except Exception:\n                score = 0.0\n        else:\n            # fallback heuristic: try to find a decimal in the output\n            m = re.search(r\"([01](?:\\.\\d+)?)\", out)\n            if m:\n                try:\n                    score = float(m.group(1))\n                except:\n                    score = 0.0\n\n        score = max(0.0, min(1.0, score))\n        refined.append((int(idx), float(score)))\n\n    refined.sort(key=lambda x: -x[1])\n    return refined\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:52:02.213624Z","iopub.execute_input":"2026-02-04T17:52:02.214238Z","iopub.status.idle":"2026-02-04T17:52:02.223664Z","shell.execute_reply.started":"2026-02-04T17:52:02.214204Z","shell.execute_reply":"2026-02-04T17:52:02.222964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def norm(s: str) -> str: \n    if not isinstance(s, str): \n        s = str(s) \n        return s.strip().lower()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:52:17.991191Z","iopub.execute_input":"2026-02-04T17:52:17.991828Z","iopub.status.idle":"2026-02-04T17:52:17.995390Z","shell.execute_reply.started":"2026-02-04T17:52:17.991794Z","shell.execute_reply":"2026-02-04T17:52:17.994727Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Full extraction per QA Pair**","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef extract_and_store_graph_edges(row):\n    qa_text = row[\"question\"] + \" \" + row[\"answer\"]\n\n    recalled = recall_edges(\n        concepts=row[\"concepts\"],\n        numbers=row[\"numbers\"],\n        units=row[\"units\"],\n        relations=row[\"relations\"],\n        qa_text=qa_text,\n        sim_threshold=0.45,\n        recall_top_k=80\n    )\n    reranked = rerank_edges(qa_text, recalled, top_k=50)\n\n    if len(reranked) > 1 and abs(reranked[0][1] - reranked[1][1]) < 0.05:\n        cot_edges = cot_disambiguate(qa_text, reranked, top_n=15)\n        cot_dict = {idx: score for idx, score in cot_edges}\n        reranked = [(idx, cot_dict.get(idx, score), *rest) for idx, score, *rest in reranked]\n\n    graph_edges = reranked[:40]   # store 40 for multi-hop\n    final_display = graph_edges[:3]\n\n    display_list = [\n        {\n            \"head\": conceptnet_df.iloc[idx][\"head\"],\n            \"relation\": conceptnet_df.iloc[idx][\"relation\"],\n            \"tail\": conceptnet_df.iloc[idx][\"tail\"],\n            \"score\": score\n        }\n        for idx, score, *rest in final_display\n    ]\n\n    # store both: display (pruned) and full graph_edges\n    return {\"display\": display_list, \"graph_edges\": graph_edges}\n\npairs_df[\"cn_result\"] = pairs_df.apply(extract_and_store_graph_edges, axis=1)\n\n# Save the graph edges column to disk (pickle)\nwith open(\"pairs_conceptnet_graph_edges.pkl\", \"wb\") as f:\n    pickle.dump(pairs_df[\"cn_result\"].tolist(), f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:52:20.197875Z","iopub.execute_input":"2026-02-04T17:52:20.198612Z","iopub.status.idle":"2026-02-04T17:55:02.144546Z","shell.execute_reply.started":"2026-02-04T17:52:20.198575Z","shell.execute_reply":"2026-02-04T17:55:02.143906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df.to_csv(\"pairs_df.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T16:39:35.545236Z","iopub.execute_input":"2026-02-04T16:39:35.545549Z","iopub.status.idle":"2026-02-04T16:39:35.570296Z","shell.execute_reply.started":"2026-02-04T16:39:35.545517Z","shell.execute_reply":"2026-02-04T16:39:35.569711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df[\"cn_result\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T17:55:42.892901Z","iopub.execute_input":"2026-02-04T17:55:42.893249Z","iopub.status.idle":"2026-02-04T17:55:42.901767Z","shell.execute_reply.started":"2026-02-04T17:55:42.893215Z","shell.execute_reply":"2026-02-04T17:55:42.901218Z"}},"outputs":[],"execution_count":null}]}