{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14899797,"datasetId":9533542,"databundleVersionId":15764433},{"sourceType":"datasetVersion","sourceId":14851504,"datasetId":9499392,"databundleVersionId":15711832}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers sentence-transformers spacy protobuf==3.20.3\n!pip install -q torch torchvision torchaudio\n!pip install -q torch-scatter torch-geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:05:42.157287Z","iopub.execute_input":"2026-02-20T14:05:42.157602Z","iopub.status.idle":"2026-02-20T14:05:54.422700Z","shell.execute_reply.started":"2026-02-20T14:05:42.157575Z","shell.execute_reply":"2026-02-20T14:05:54.421728Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nimport pandas as pd\nimport numpy as np\nimport spacy\nimport ast\nfrom typing import List, Dict\nfrom sentence_transformers import SentenceTransformer, CrossEncoder\nfrom transformers import pipeline\nimport torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:07:49.463903Z","iopub.execute_input":"2026-02-20T14:07:49.464591Z","iopub.status.idle":"2026-02-20T14:07:55.556253Z","shell.execute_reply.started":"2026-02-20T14:07:49.464551Z","shell.execute_reply":"2026-02-20T14:07:55.555418Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"pairs_df = pd.read_csv(\"/kaggle/input/datasets/mahbubahabib/blessme/BLESSINGS.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:07:55.557657Z","iopub.execute_input":"2026-02-20T14:07:55.558503Z","iopub.status.idle":"2026-02-20T14:07:55.645864Z","shell.execute_reply.started":"2026-02-20T14:07:55.558469Z","shell.execute_reply":"2026-02-20T14:07:55.645098Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"pairs_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:07:55.646965Z","iopub.execute_input":"2026-02-20T14:07:55.647505Z","iopub.status.idle":"2026-02-20T14:07:55.683375Z","shell.execute_reply.started":"2026-02-20T14:07:55.647460Z","shell.execute_reply":"2026-02-20T14:07:55.682751Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      qid                                           question  is_correct  \\\n0       0                         the sun is responsible for           0   \n1       0                         the sun is responsible for           0   \n2       0                         the sun is responsible for           0   \n3       0                         the sun is responsible for           1   \n4       1       when standing miles away from mount rushmore           0   \n...   ...                                                ...         ...   \n1195  298  what is an example of reproduction occurring i...           1   \n1196  299  because of human logging activities, some anim...           0   \n1197  299  because of human logging activities, some anim...           0   \n1198  299  because of human logging activities, some anim...           0   \n1199  299  because of human logging activities, some anim...           1   \n\n     correct_vector                                             answer  \\\n0      [0, 0, 0, 1]                        puppies learning new tricks   \n1      [0, 0, 0, 1]                children growing up and getting old   \n2      [0, 0, 0, 1]                          flowers wilting in a vase   \n3      [0, 0, 0, 1]             plants sprouting, blooming and wilting   \n4      [0, 0, 0, 1]                      the mountains seem very close   \n...             ...                                                ...   \n1195   [0, 0, 0, 1]  cats are unable to produce offspring until the...   \n1196   [0, 0, 0, 1]                                                air   \n1197   [0, 0, 0, 1]                                              water   \n1198   [0, 0, 0, 1]                                               legs   \n1199   [0, 0, 0, 1]                                               food   \n\n                                               concepts numbers  units  \\\n0     ['responsible', 'sun', 'learn', 'puppy', 'tric...      []     []   \n1     ['responsible', 'get', 'child', 'old', 'grow',...      []     []   \n2      ['responsible', 'vase', 'flower', 'sun', 'wilt']      []     []   \n3     ['responsible', 'sprout', 'bloom', 'plant', 's...      []  ['m']   \n4     ['rushmore', 'stand', 'mountain', 'mount', 'mi...      []  ['m']   \n...                                                 ...     ...    ...   \n1195  ['occur', 'reproduction', 'adulthood', 'unable...      []  ['m']   \n1196  ['activity', 'conserve', 'air', 'logging', 'hu...      []  ['m']   \n1197  ['activity', 'conserve', 'logging', 'human', '...      []  ['m']   \n1198  ['activity', 'leg', 'conserve', 'logging', 'hu...      []  ['m']   \n1199  ['activity', 'food', 'conserve', 'logging', 'h...      []  ['m']   \n\n        relations                                          cn_result  \n0              []  {'display': [{'head': 'small_dog', 'relation':...  \n1              []  {'display': [{'head': 'sun', 'relation': 'used...  \n2              []  {'display': [{'head': 'wiltja', 'relation': 'r...  \n3              []  {'display': [{'head': 'sun', 'relation': 'rela...  \n4              []  {'display': [{'head': 'mount_rushmore', 'relat...  \n...           ...                                                ...  \n1195           []  {'display': [{'head': 'cat', 'relation': 'rela...  \n1196  ['because']  {'display': [{'head': 'air', 'relation': 'rela...  \n1197  ['because']  {'display': [{'head': 'animal', 'relation': 'r...  \n1198  ['because']  {'display': [{'head': 'human', 'relation': 're...  \n1199  ['because']  {'display': [{'head': 'preserve', 'relation': ...  \n\n[1200 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question</th>\n      <th>is_correct</th>\n      <th>correct_vector</th>\n      <th>answer</th>\n      <th>concepts</th>\n      <th>numbers</th>\n      <th>units</th>\n      <th>relations</th>\n      <th>cn_result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>the sun is responsible for</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>puppies learning new tricks</td>\n      <td>['responsible', 'sun', 'learn', 'puppy', 'tric...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'small_dog', 'relation':...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>the sun is responsible for</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>children growing up and getting old</td>\n      <td>['responsible', 'get', 'child', 'old', 'grow',...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'sun', 'relation': 'used...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>the sun is responsible for</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>flowers wilting in a vase</td>\n      <td>['responsible', 'vase', 'flower', 'sun', 'wilt']</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'wiltja', 'relation': 'r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>the sun is responsible for</td>\n      <td>1</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>plants sprouting, blooming and wilting</td>\n      <td>['responsible', 'sprout', 'bloom', 'plant', 's...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'sun', 'relation': 'rela...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>when standing miles away from mount rushmore</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>the mountains seem very close</td>\n      <td>['rushmore', 'stand', 'mountain', 'mount', 'mi...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'mount_rushmore', 'relat...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>298</td>\n      <td>what is an example of reproduction occurring i...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>cats are unable to produce offspring until the...</td>\n      <td>['occur', 'reproduction', 'adulthood', 'unable...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>[]</td>\n      <td>{'display': [{'head': 'cat', 'relation': 'rela...</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>299</td>\n      <td>because of human logging activities, some anim...</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>air</td>\n      <td>['activity', 'conserve', 'air', 'logging', 'hu...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>['because']</td>\n      <td>{'display': [{'head': 'air', 'relation': 'rela...</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>299</td>\n      <td>because of human logging activities, some anim...</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>water</td>\n      <td>['activity', 'conserve', 'logging', 'human', '...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>['because']</td>\n      <td>{'display': [{'head': 'animal', 'relation': 'r...</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>299</td>\n      <td>because of human logging activities, some anim...</td>\n      <td>0</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>legs</td>\n      <td>['activity', 'leg', 'conserve', 'logging', 'hu...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>['because']</td>\n      <td>{'display': [{'head': 'human', 'relation': 're...</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>299</td>\n      <td>because of human logging activities, some anim...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>food</td>\n      <td>['activity', 'food', 'conserve', 'logging', 'h...</td>\n      <td>[]</td>\n      <td>['m']</td>\n      <td>['because']</td>\n      <td>{'display': [{'head': 'preserve', 'relation': ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:05:13.031438Z","iopub.execute_input":"2026-02-20T14:05:13.032182Z","iopub.status.idle":"2026-02-20T14:05:13.139488Z","shell.execute_reply.started":"2026-02-20T14:05:13.032150Z","shell.execute_reply":"2026-02-20T14:05:13.138719Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",          # CPU/GPU auto\n    torch_dtype=torch.float16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:01:43.982305Z","iopub.execute_input":"2026-02-20T14:01:43.982893Z","iopub.status.idle":"2026-02-20T14:03:13.985658Z","shell.execute_reply.started":"2026-02-20T14:01:43.982863Z","shell.execute_reply":"2026-02-20T14:03:13.985028Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n2026-02-20 14:02:05.857622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771596126.215786     364 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771596126.312187     364 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771596127.222202     364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771596127.222242     364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771596127.222245     364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771596127.222247     364 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72466b138804535a261b0c59e9f2aa6"}},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"extra 1","metadata":{}},{"cell_type":"markdown","source":"extra 2","metadata":{}},{"cell_type":"code","source":"def mistral_pick(question, options):\n    prompt = f\"\"\"You are a multiple choice question solver.\nChoose the correct option index.\n\nQuestion: {question}\n\nOptions:\n\"\"\"\n    for i, opt in enumerate(options):\n        prompt += f\"{i}. {opt}\\n\"\n\n    prompt += \"\\nReply ONLY with a single number: 0, 1, 2, or 3.\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=3,\n            do_sample=False,\n            temperature=0.0\n        )\n\n    text = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    import re\n    m = re.search(r\"\\b[0-3]\\b\", text)\n    if m:\n        return int(m.group())\n    else:\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:20:11.234982Z","iopub.execute_input":"2026-02-20T14:20:11.235580Z","iopub.status.idle":"2026-02-20T14:20:11.241525Z","shell.execute_reply.started":"2026-02-20T14:20:11.235541Z","shell.execute_reply":"2026-02-20T14:20:11.240769Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def mistral_pick(question, options):\n    prompt = f\"\"\"<s>[INST]\nChoose the correct answer.\n\nQuestion: {question}\n\nOptions:\n\"\"\"\n    for i, opt in enumerate(options):\n        prompt += f\"{i}. {opt}\\n\"\n\n    prompt += \"Reply ONLY with the index number (0,1,2,3). [/INST]\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=5,\n            do_sample=False\n        )\n\n    text = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    # extract digit\n    import re\n    m = re.search(r\"\\b[0-3]\\b\", text)\n    if m:\n        return int(m.group())\n    else:\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:09:59.765158Z","iopub.execute_input":"2026-02-20T14:09:59.766083Z","iopub.status.idle":"2026-02-20T14:09:59.771427Z","shell.execute_reply.started":"2026-02-20T14:09:59.766043Z","shell.execute_reply":"2026-02-20T14:09:59.770785Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"Which is the suitable temperature for photosynthesis?\"\noptions = [\n    \"12°C - 25°C\",\n    \"17°C - 30°C\",\n    \"22°C - 35°C\",\n    \"27°C - 40°C\"\n]\n\nidx = mistral_pick(question, options)\nprint(\"Predicted index:\", idx)\nprint(\"Predicted answer:\", options[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:05:20.135931Z","iopub.execute_input":"2026-02-20T14:05:20.136571Z","iopub.status.idle":"2026-02-20T14:05:21.905108Z","shell.execute_reply.started":"2026-02-20T14:05:20.136540Z","shell.execute_reply":"2026-02-20T14:05:21.904317Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Predicted index: 0\nPredicted answer: 12°C - 25°C\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pairs_df[\"llm_ans_label\"] = 0\n\nfor qid, group in pairs_df.groupby(\"qid\"):\n    question = group[\"question\"].iloc[0]\n    options = group[\"answer\"].tolist()\n\n    idx = mistral_pick(question, options)\n\n    if idx is not None and idx < len(group):\n        correct_row = group.index[idx]\n        pairs_df.loc[correct_row, \"llm_ans_label\"] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:10:05.819965Z","iopub.execute_input":"2026-02-20T14:10:05.820575Z","iopub.status.idle":"2026-02-20T14:12:13.756278Z","shell.execute_reply.started":"2026-02-20T14:10:05.820538Z","shell.execute_reply":"2026-02-20T14:12:13.755568Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"pairs_df[\"concept_ans_label\"] = 0\n\nfor qid, group in pairs_df.groupby(\"qid\"):\n    correct_row = group[group[\"is_correct\"] == 1]\n    if len(correct_row) == 0:\n        continue\n\n    answer = correct_row[\"answer\"].iloc[0].lower()\n    extract_text = \" \".join(group[\"is_correct\"].astype(str)).lower()\n\n    if answer in extract_text:\n        pairs_df.loc[correct_row.index, \"concept_ans_label\"] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:14:59.416066Z","iopub.execute_input":"2026-02-20T14:14:59.416700Z","iopub.status.idle":"2026-02-20T14:14:59.615878Z","shell.execute_reply.started":"2026-02-20T14:14:59.416668Z","shell.execute_reply":"2026-02-20T14:14:59.615297Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Save dataframe with new columns\npairs_df.to_csv(\"hope.csv\", index=False)\n\nprint(\"Saved as pairs_df_with_labels.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:35:04.952944Z","iopub.execute_input":"2026-02-16T13:35:04.95323Z","iopub.status.idle":"2026-02-16T13:35:05.342956Z","shell.execute_reply.started":"2026-02-16T13:35:04.95319Z","shell.execute_reply":"2026-02-16T13:35:05.342241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:42:47.39391Z","iopub.execute_input":"2026-02-16T13:42:47.394674Z","iopub.status.idle":"2026-02-16T13:42:47.40919Z","shell.execute_reply.started":"2026-02-16T13:42:47.394638Z","shell.execute_reply":"2026-02-16T13:42:47.408446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# total correct predictions\nllm_correct = (pairs_df[\"llm_ans_label\"] == pairs_df[\"is_correct\"]).sum()\n\n# total samples\ntotal = len(pairs_df)\n\nllm_accuracy = llm_correct / total\n\nprint(\"LLM Accuracy:\", llm_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:15:54.627613Z","iopub.execute_input":"2026-02-20T14:15:54.628083Z","iopub.status.idle":"2026-02-20T14:15:54.633965Z","shell.execute_reply.started":"2026-02-20T14:15:54.628044Z","shell.execute_reply":"2026-02-20T14:15:54.633184Z"}},"outputs":[{"name":"stdout","text":"LLM Accuracy: 0.6783333333333333\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"concept_correct = (pairs_df[\"concept_ans_label\"] == pairs_df[\"is_correct\"]).sum()\n\nconcept_accuracy = concept_correct / total\n\nprint(\"Concept Accuracy:\", concept_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:16:10.691216Z","iopub.execute_input":"2026-02-20T14:16:10.691929Z","iopub.status.idle":"2026-02-20T14:16:10.696682Z","shell.execute_reply.started":"2026-02-20T14:16:10.691889Z","shell.execute_reply":"2026-02-20T14:16:10.695641Z"}},"outputs":[{"name":"stdout","text":"Concept Accuracy: 0.75\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"true_positive = ((pairs_df[\"is_correct\"] == 1) & (pairs_df[\"llm_ans_label\"] == 1)).sum()\ntotal_true = (pairs_df[\"is_correct\"] == 1).sum()\n\nllm_recall = true_positive / total_true\n\nprint(\"LLM Recall (only label=1):\", llm_recall)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:16:23.044077Z","iopub.execute_input":"2026-02-20T14:16:23.044665Z","iopub.status.idle":"2026-02-20T14:16:23.050534Z","shell.execute_reply.started":"2026-02-20T14:16:23.044630Z","shell.execute_reply":"2026-02-20T14:16:23.049740Z"}},"outputs":[{"name":"stdout","text":"LLM Recall (only label=1): 0.3566666666666667\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:37:55.300573Z","iopub.execute_input":"2026-02-20T14:37:55.301527Z","iopub.status.idle":"2026-02-20T14:37:59.122092Z","shell.execute_reply.started":"2026-02-20T14:37:55.301469Z","shell.execute_reply":"2026-02-20T14:37:59.121125Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0rc2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    quantization_config=bnb_config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:38:04.601814Z","iopub.execute_input":"2026-02-20T14:38:04.602217Z","iopub.status.idle":"2026-02-20T14:38:04.724288Z","shell.execute_reply.started":"2026-02-20T14:38:04.602169Z","shell.execute_reply":"2026-02-20T14:38:04.723070Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_364/3182512549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LazyAutoMappingValue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         mapping_values = [\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m str_to_torch_dtype = {\n\u001b[1;32m    276\u001b[0m     \u001b[0;34m\"BOOL\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;34m\"U8\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;34m\"I8\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;34m\"I16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py\u001b[0m in \u001b[0;36mget_hf_quantizer\u001b[0;34m(config, quantization_config, dtype, from_tf, from_flax, device_map, weights_only, user_agent)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             )\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# 4 bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"],"ename":"ImportError","evalue":"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"def mistral_pick(question, options):\n    prompt = f\"\"\"<s>[INST]\nChoose the correct answer.\n\nQuestion: {question}\n\nOptions:\n\"\"\"\n    for i, opt in enumerate(options):\n        prompt += f\"{i}. {opt}\\n\"\n\n    prompt += \"Reply ONLY with the index number (0,1,2,3). [/INST]\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=5,\n            do_sample=False\n        )\n\n    text = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    # extract digit\n    import re\n    m = re.search(r\"\\b[0-3]\\b\", text)\n    if m:\n        return int(m.group())\n    else:\n        return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df[\"llm_ans_label\"] = 0\n\nfor qid, group in pairs_df.groupby(\"qid\"):\n    question = group[\"question\"].iloc[0]\n    options = group[\"answer\"].tolist()\n\n    idx = mistral_pick(question, options)\n\n    if idx is not None and idx < len(group):\n        correct_row = group.index[idx]\n        pairs_df.loc[correct_row, \"llm_ans_label\"] = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T14:19:24.575181Z","iopub.status.idle":"2026-02-20T14:19:24.575507Z","shell.execute_reply.started":"2026-02-20T14:19:24.575343Z","shell.execute_reply":"2026-02-20T14:19:24.575372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_df[\"concept_ans_label\"] = 0\n\nfor qid, group in pairs_df.groupby(\"qid\"):\n    correct_row = group[group[\"llm_ans_label\"] == 1]\n    if len(correct_row) == 0:\n        continue\n\n    answer = correct_row[\"answer\"].iloc[0].lower()\n    extract_text = \" \".join(group[\"all_extract\"].astype(str)).lower()\n\n    if answer in extract_text:\n        pairs_df.loc[correct_row.index, \"concept_ans_label\"] = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"concept_correct = (pairs_df[\"concept_ans_label\"] == pairs_df[\"label\"]).sum()\n\nconcept_accuracy = concept_correct / total\n\nprint(\"Concept Accuracy:\", concept_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# total correct predictions\nllm_correct = (pairs_df[\"llm_ans_label\"] == pairs_df[\"label\"]).sum()\n\n# total samples\ntotal = len(pairs_df)\n\nllm_accuracy = llm_correct / total\n\nprint(\"LLM Accuracy:\", llm_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"concept_correct = (pairs_df[\"concept_ans_label\"] == pairs_df[\"label\"]).sum()\n\nconcept_accuracy = concept_correct / total\n\nprint(\"Concept Accuracy:\", concept_accuracy)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_positive = ((pairs_df[\"label\"] == 1) & (pairs_df[\"llm_ans_label\"] == 1)).sum()\ntotal_true = (pairs_df[\"label\"] == 1).sum()\n\nllm_recall = true_positive / total_true\n\nprint(\"LLM Recall (only label=1):\", llm_recall)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}